{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superior-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "talented-louis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./ckpt/dataset.pkl', 'rb') as fp:\n",
    "    dic = pickle.load(fp)\n",
    "    mac_list = dic['mac_list']\n",
    "len(mac_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-socket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monetary-caution",
   "metadata": {},
   "source": [
    "## Read Inference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understanding-credits",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 61, 61]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_srcs = ['./data_inference/']\n",
    "\n",
    "#################################################\n",
    "##############  read training data  #############\n",
    "\n",
    "# read training data\n",
    "wlan_dfs_test = []\n",
    "for wlan in ['wlan0', 'wlan1', 'wlan2']:\n",
    "    df_cat = None\n",
    "    for data_src in data_srcs:\n",
    "        df = pd.read_csv(f'{data_src}/{wlan.strip()}/x_-1.0_y_-1.0_z_-1.0_log.csv')\n",
    "        df_cat = df if df is None else pd.concat([df_cat, df])\n",
    "    wlan_dfs_test.append(df_cat)\n",
    "\n",
    "# # read training data\n",
    "# df = pd.read_csv(f'./data_won_test/wlan012.csv')\n",
    "# wlan_dfs_test = []\n",
    "# for wlan in ['wlan0', 'wlan1', 'wlan2']:\n",
    "#     wlan_dfs_test.append( df.loc[df['name']==f'{wlan}'].iloc[:, 2:] )\n",
    "\n",
    "#################################################\n",
    "##############  data preprocessing  #############\n",
    "\n",
    "# 取 exp : y = e^(-x/80)\n",
    "normalized_wlan_dfs_test = []\n",
    "for wlan_df in wlan_dfs_test:\n",
    "    sel_indexs = list(wlan_df.columns)[4:]\n",
    "    wlan_df = wlan_df.copy()\n",
    "    wlan_df[sel_indexs] = (-wlan_df[sel_indexs]/80)#.apply(np.exp)\n",
    "    normalized_wlan_dfs_test.append(wlan_df)\n",
    "\n",
    "# # find clean mac list\n",
    "# for i in range(3):\n",
    "#     wlan_df = normalized_wlan_dfs[i]\n",
    "    \n",
    "#     mac_list = []\n",
    "#     for mac_, na_ in zip(wlan_df.columns[4:], wlan_df.isna().sum()[4:]):\n",
    "#         if na_ < len(wlan_df)*0.40:\n",
    "#             mac_list.append(mac_)\n",
    "\n",
    "# mac_list = sorted(list(set(mac_list)))\n",
    "    \n",
    "# make clean mac df\n",
    "normalized_cleaned_wlan_dfs_test = []\n",
    "for i in range(3):\n",
    "    wlan_df = normalized_wlan_dfs_test[i]    \n",
    "    selec_col = ['x','y','z','timestamp'] + mac_list\n",
    "    df = pd.DataFrame(data={col:wlan_df[col] if col in wlan_df.columns else [np.nan] * len(wlan_df) for col in selec_col})\n",
    "    normalized_cleaned_wlan_dfs_test.append(df)\n",
    "\n",
    "# fill nan to 0\n",
    "for i in range(3):\n",
    "    normalized_cleaned_wlan_dfs_test[i] = normalized_cleaned_wlan_dfs_test[i].fillna(0)\n",
    "    \n",
    "[len(normalized_cleaned_wlan_dfs_test[i].columns) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-freedom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-gothic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "grateful-electricity",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Wlan0,1,2並起來, Random Training data 5x5x5 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arranged-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################################\n",
    "############################## Test ###############################\n",
    "\n",
    "X_test, Y_test = [], []\n",
    "\n",
    "# 5*5*5\n",
    "for idx1, row1 in normalized_cleaned_wlan_dfs_test[0].iterrows():\n",
    "    x1 = row1.values[0]\n",
    "    y1 = row1.values[1]\n",
    "    signals1 = row1.values[4:]\n",
    "    for idx2, row2 in normalized_cleaned_wlan_dfs_test[1].iterrows():\n",
    "        x2 = row2.values[0]\n",
    "        y2 = row2.values[1]\n",
    "        signals2 = row2.values[4:]\n",
    "        if x2!=x1 or y2!=y1:\n",
    "            continue\n",
    "        else:\n",
    "            for idx3, row3 in normalized_cleaned_wlan_dfs_test[2].iterrows():\n",
    "                x3 = row3.values[0]\n",
    "                y3 = row3.values[1]\n",
    "                signals3 = row3.values[4:]\n",
    "                if x3!=x2 or y3!=y2:\n",
    "                    continue\n",
    "                else:\n",
    "                    X_test.append(np.concatenate([signals1,signals2,signals3]))\n",
    "                    Y_test.append([x1,y1])\n",
    "\n",
    "#                     normalized_cleaned_wlan_dfs_test[2].drop(idx3, inplace=True)\n",
    "#                     break\n",
    "#             normalized_cleaned_wlan_dfs_test[1].drop(idx2, inplace=True)\n",
    "#             break\n",
    "\n",
    "X_test, Y_test = np.stack(X_test), np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "musical-fifth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 171), (96, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-california",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-assets",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "solved-coordinator",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scenic-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=64, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(in_dim, hid_dim, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(hid_dim),\n",
    "            \n",
    "#             nn.Dropout(0.5),\n",
    "            nn.Linear(hid_dim, hid_dim, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(hid_dim),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hid_dim, hid_dim, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(hid_dim),\n",
    "                        \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hid_dim, out_dim, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regular-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=171, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (8): Tanh()\n",
       "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "model = Model(in_dim=X_test.shape[1])\n",
    "model.load_state_dict(torch.load('./ckpt/best.pt', map_location='cpu')['model'])\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acquired-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(Y_test))\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=256)\n",
    "\n",
    "\n",
    "mse, n = 0, 0\n",
    "pred, answ = [], []\n",
    "for x, y_ in test_loader:\n",
    "    y = model(x.cuda().float())\n",
    "    \n",
    "    pred.append(y.cpu().detach())\n",
    "    answ.append(y_.cpu().detach())\n",
    "\n",
    "pred = torch.cat(pred)\n",
    "answ = torch.cat(answ)\n",
    "    \n",
    "# # mse \n",
    "# mse = torch.nn.MSELoss()(pred, answ)\n",
    "# float(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "actual-spray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_aug = []\n",
    "answ_aug = []\n",
    "x,y = 0,0\n",
    "tmp = []\n",
    "for i in range(len(answ)):\n",
    "    x_, y_ = answ[i]\n",
    "    if x==x_ and y==y_:\n",
    "        tmp.append(pred[i])\n",
    "    else:\n",
    "        if len(tmp)!=0:\n",
    "            pred_aug.append(torch.stack(tmp).mean(axis=0))\n",
    "            answ_aug.append(ans)\n",
    "        tmp = [pred[i]]\n",
    "        ans = answ[i]\n",
    "        x, y = x_, y_\n",
    "pred_aug.append(torch.stack(tmp).mean(axis=0))\n",
    "answ_aug.append(ans)\n",
    "        \n",
    "pred_aug = torch.stack(pred_aug)\n",
    "answ_aug = torch.stack(answ_aug)\n",
    "\n",
    "len(pred_aug), len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sacred-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.8478217 1.5498332] [-1. -1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(answ_aug)):\n",
    "    print(pred_aug[i].numpy(), answ_aug[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-agriculture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-florida",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
